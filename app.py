# -*- coding: utf-8 -*-
"""
Created on Thu Nov  6 10:49:47 2025

@author: ADMIN
"""

# -------------------------------------------------------------
# üß© CUSTOMER SEGMENTATION DASHBOARD USING K-MEANS CLUSTERING
# -------------------------------------------------------------

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score

# Streamlit Page Setup
st.set_page_config(page_title="Customer Segmentation", layout="wide")
st.title("üß© Customer Segmentation Dashboard")

# -------------------------------------------------------------
# 1Ô∏è‚É£ Load the Dataset
# -------------------------------------------------------------
file_path = r"E:\jd\segmented_customers.csv"   # ‚úÖ Your exact file path

try:
    df = pd.read_csv(file_path)
    st.success("‚úÖ Data loaded successfully!")
except FileNotFoundError:
    st.error(f"‚ùå File not found at: {file_path}")
    st.stop()

st.subheader("üìã Dataset Preview")
st.dataframe(df.head())

# -------------------------------------------------------------
# 2Ô∏è‚É£ Data Cleaning
# -------------------------------------------------------------
df.columns = df.columns.str.strip()  # remove extra spaces

# Fill missing numeric values with median
for col in df.select_dtypes(include='number').columns:
    df[col].fillna(df[col].median(), inplace=True)

# Encode categorical columns
for col in df.select_dtypes(include='object').columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col].astype(str))

st.success("‚úÖ Data cleaning completed!")

# -------------------------------------------------------------
# 3Ô∏è‚É£ Exploratory Data Analysis (EDA)
# -------------------------------------------------------------
st.header("üîç Exploratory Data Analysis (EDA)")

col1, col2 = st.columns(2)

with col1:
    st.subheader("üìä Distribution of Annual Income")
    fig, ax = plt.subplots(figsize=(6,4))
    sns.histplot(df['Annual Income'], kde=True, color='skyblue', ax=ax)
    st.pyplot(fig)

with col2:
    st.subheader("üì¶ Spending Score Distribution")
    fig, ax = plt.subplots(figsize=(6,4))
    sns.boxplot(y=df['Spending Score'], color='lightgreen', ax=ax)
    st.pyplot(fig)

st.subheader("üìà Correlation Heatmap")
fig, ax = plt.subplots(figsize=(8,5))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm', ax=ax)
st.pyplot(fig)

# -------------------------------------------------------------
# 4Ô∏è‚É£ Feature Scaling
# -------------------------------------------------------------
st.header("‚öôÔ∏è Feature Scaling & Model Preparation")
features = ['Age', 'Annual Income', 'Spending Score']
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df[features])

st.success("‚úÖ Features scaled successfully!")

# -------------------------------------------------------------
# 5Ô∏è‚É£ Determine Optimal K using Elbow & Silhouette Methods
# -------------------------------------------------------------
st.header("üìä Determine Optimal Number of Clusters")

inertia = []
sil_scores = []

for k in range(2, 11):
    kmeans = KMeans(n_clusters=k, random_state=42)
    labels = kmeans.fit_predict(df_scaled)
    inertia.append(kmeans.inertia_)
    sil_scores.append(silhouette_score(df_scaled, labels))

col1, col2 = st.columns(2)

with col1:
    st.subheader("Elbow Method")
    fig, ax = plt.subplots()
    plt.plot(range(2, 11), inertia, marker='o')
    plt.xlabel("Number of Clusters")
    plt.ylabel("Inertia")
    plt.title("Elbow Method")
    st.pyplot(fig)

with col2:
    st.subheader("Silhouette Score")
    fig, ax = plt.subplots()
    plt.plot(range(2, 11), sil_scores, marker='o', color='red')
    plt.xlabel("Number of Clusters")
    plt.ylabel("Silhouette Score")
    plt.title("Silhouette Method")
    st.pyplot(fig)

optimal_k = st.slider("Select Optimal Number of Clusters (K)", 2, 10, 3)

# -------------------------------------------------------------
# 6Ô∏è‚É£ Apply K-Means Clustering
# -------------------------------------------------------------
kmeans = KMeans(n_clusters=optimal_k, random_state=42)
df['Cluster'] = kmeans.fit_predict(df_scaled)

st.success(f"‚úÖ K-Means applied with K = {optimal_k}")

st.subheader("üìç Cluster Counts")
st.bar_chart(df['Cluster'].value_counts())

# -------------------------------------------------------------
# 7Ô∏è‚É£ PCA Visualization (2D)
# -------------------------------------------------------------
st.header("üé® PCA Visualization of Clusters")

pca = PCA(n_components=2)
components = pca.fit_transform(df_scaled)

fig, ax = plt.subplots(figsize=(8,6))
sns.scatterplot(x=components[:,0], y=components[:,1],
                hue=df['Cluster'], palette='viridis', s=70)
plt.xlabel("PCA 1")
plt.ylabel("PCA 2")
plt.title("Customer Segments (PCA Visualization)")
st.pyplot(fig)

# -------------------------------------------------------------
# 8Ô∏è‚É£ Cluster Profiling
# -------------------------------------------------------------
st.header("üìã Cluster Profiling")

cluster_profile = df.groupby('Cluster')[features].mean().round(2)
st.dataframe(cluster_profile)

st.markdown("""
- üü¢ **Cluster 0**: High income, high spending customers  
- üü£ **Cluster 1**: Moderate income and spending  
- üü° **Cluster 2**: Low income, low spending customers
""")

# -------------------------------------------------------------
# ‚úÖ Footer
# -------------------------------------------------------------
st.markdown("---")
st.markdown("Developed with ‚ù§Ô∏è using **Streamlit**, **Scikit-learn**, and **Pandas**.")
