#  Import Libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.decomposition import PCA

# 2. Load your CSV data
df = pd.read_csv(r"E:\jd\customer_segmentation_dataset.csv") 

df.head()
df.info()
df.describe()

df.duplicated().sum()

#missing values
df.isnull().sum()

# Clean column names (remove extra spaces)
df.columns = df.columns.str.strip()

# Fill missing values (if any) with median
df['Spending Score'] = df['Spending Score'].fillna(df['Spending Score'].median())
df['Tenure (Years)'] = df['Tenure (Years)'].fillna(df['Tenure (Years)'].median())

# Encode categorical variables if exist
if 'Gender' in df.columns:
    le = LabelEncoder()
    df['Gender'] = le.fit_transform(df['Gender'])
    
     #Histogram 
sns.histplot(df['Annual Income'], kde=True)
plt.show()

plt.figure(figsize=(8,5))
sns.boxplot(y=df['Annual Income'])
plt.title('Boxplot of Annual Income')
plt.ylabel('Annual Income')
plt.show()


# Remove commas and convert AnnualIncome to numeric
df['Annual Income'] = df['Annual Income'].replace(',', '', regex=True).astype(float)
df['Annual Income'] = df['Annual Income'].replace(',', '', regex=True).astype(float)

for col in ['Annual Income', 'Spending Score', 'Tenure (Years)']:
    df[col] = df[col].replace(',', '', regex=True)
    df[col] = pd.to_numeric(df[col], errors='coerce')

import seaborn as sns
import matplotlib.pyplot as plt

sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

# 5. Scaling
features = ['Age', 'Annual Income', 'Spending Score']  # Use columns you want to cluster
df_scaled = StandardScaler().fit_transform(df[features])

 6. Determine Optimal Clusters
inertia = []
sil_scores = []

for k in range(2, 11):
    kmeans = KMeans(n_clusters=k, random_state=42)
    labels = kmeans.fit_predict(df_scaled)
    inertia.append(kmeans.inertia_)
    sil_scores.append(silhouette_score(df_scaled, labels))
    
    # Plot Elbow Method
plt.plot(range(2, 11), inertia, marker='o')
plt.xlabel('Number of Clusters')
plt.ylabel('Inertia')
plt.title('Elbow Method')
plt.show()

# Plot Silhouette Scores
plt.plot(range(2, 11), sil_scores, marker='o', color='red')
plt.xlabel('Number of Clusters')
plt.ylabel('Silhouette Score')
plt.title('Silhouette Scores')
plt.show()

# 7. Apply K-Means (choose optimal clusters, e.g., 3)
kmeans = KMeans(n_clusters=3, random_state=42)
df['Cluster'] = kmeans.fit_predict(df_scaled)

# 8. Visualize Clusters using PCA
pca = PCA(n_components=2)
principal_components = pca.fit_transform(df_scaled)
plt.scatter(principal_components[:,0], principal_components[:,1], c=df['Cluster'], cmap='viridis')
plt.xlabel('PCA 1')
plt.ylabel('PCA 2')
plt.title('Customer Segments')
plt.show()

# Mean for numeric columns
cluster_numeric = df.select_dtypes(include='number').groupby(df['Cluster']).mean()

# Most common category for categorical columns
cluster_categorical = df.select_dtypes(exclude='number').groupby(df['Cluster']).agg(lambda x: x.mode()[0])

# Combine both
cluster_profile = pd.concat([cluster_numeric, cluster_categorical], axis=1)

print("\nCluster Profile:")
print(cluster_profile)

































